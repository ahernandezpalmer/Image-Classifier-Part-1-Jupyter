{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "import os, random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "\n",
    "\n",
    "data_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=data_transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(15),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(250),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "valid_transforms= transforms.Compose([transforms.Resize(250),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir,transform=valid_transforms)\n",
    "                            \n",
    "image_datasets = train_data, test_data, valid_data                                     \n",
    "\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "    \n",
    "print(cat_to_name)\n",
    "print(\"\\n Length\", len(cat_to_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build and train your network\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# turn off gradients for the model\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    " # define our new classifier\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(nn.Linear(25088, 1024),           \n",
    "                           nn.ReLU(),\n",
    "                           nn.Dropout(p=0.2),\n",
    "                           nn.Linear(1024,512),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Dropout(p=0.2),\n",
    "                           nn.Linear(512 ,102),\n",
    "                           nn.LogSoftmax(dim=1))\n",
    "\n",
    "model.classifier = classifier\n",
    "\n",
    "# define the criterion and optimizer and move the model to any device avaiable \n",
    "\n",
    "criterion = nn.NLLLoss()      # define the loss\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)    # optimizer\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do validation on the test set\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 3\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 42\n",
    "model.to(device)\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in trainloader:\n",
    "        steps += 1\n",
    "        # Move images and label tensors to the default device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logps = model.forward(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            valid_loss = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for images, labels in validloader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    logps = model.forward(images)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    valid_loss += batch_loss.item()\n",
    "                    # Calculate accuracy\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                     \n",
    "                   \n",
    "                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Valid loss: {valid_loss/len(validloader):.3f}.. \"\n",
    "                  f\"Valid accuracy: {accuracy/len(validloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save the checkpoint \n",
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.class_to_idx = train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 25088,\n",
    "              'output_size': 102,\n",
    "              'hidden_layer1': 1024,\n",
    "              'hidden_layer2':512,\n",
    "              'learning rate':0.001,\n",
    "              'classifier':classifier,\n",
    "              'epochs':4,\n",
    "              'optimizer':optimizer.state_dict,\n",
    "              'class_to_idx':model.class_to_idx,\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "optimizer.state_dict\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layer1'],\n",
    "                             checkpoint['hidden_layer2'],\n",
    "                             checkpoint['learning rate'],\n",
    "                             checkpoint['classifier'],\n",
    "                             checkpoint['epochs'],\n",
    "                             checkpoint['optimizer'])\n",
    "    \n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def process_image(im):\n",
    "    \n",
    "   \n",
    "    im = Image.open(im)\n",
    "    width, height = im.size\n",
    "    \n",
    "    if width > height:\n",
    "        ratio =float(width)/float(height)\n",
    "        im.thumbnail((ratio*256,256))\n",
    "        \n",
    "    elif height>width:\n",
    "        ratio =float(width)/float(height)\n",
    "        im.thumbnail((256,ratio*256))\n",
    "        \n",
    "    new_width, new_height = im.size  #size of resized image\n",
    "    \n",
    "    left = (new_width-224)/2\n",
    "    top = (new_height-224)/2\n",
    "    right = (new_width +224)/2\n",
    "    bottom = (new_height+224)/2\n",
    "    im=im.crop((left, top, right, bottom))\n",
    "    \n",
    "    np_image=np.array(im)\n",
    "    np_image=np_image/255\n",
    "    \n",
    "    means=np.array([0.485,0.456,0.406])\n",
    "    std=np.array([0.229,0.224,0.225])\n",
    "    \n",
    "    np_image=(np_image-means)/std\n",
    "    np_image=np_image.transpose((2,0,1))\n",
    "    \n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = np.array(image).transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image='flowers/test/98/image_07753.jpg'\n",
    "processed_image = process_image(image)\n",
    "imshow(processed_image)\n",
    "processed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    # TODO: Implement the code to predict the class from an image file\n",
    "\n",
    "    \n",
    "def predict(image_path, model, topk=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    image=process_image(image_path)\n",
    "    image=torch.from_numpy(np.array([image])).float()\n",
    "    \n",
    "    image=Variable(image)\n",
    "    image=image.to(device)\n",
    "    output=model.forward(image)\n",
    "     \n",
    "    probability = torch.exp(output).data\n",
    "    probs = torch.topk(probability,topk)[0].tolist()[0]\n",
    "    indices = torch.topk(probability,topk)[1].tolist()[0]\n",
    "    \n",
    "    ind = []\n",
    "    for i in range(len(model.class_to_idx.items())):\n",
    "        ind.append(list(model.class_to_idx.items())[i][0])\n",
    "        \n",
    "    label = []\n",
    "    for i in range(5):\n",
    "        label.append(ind[indices[i]])\n",
    "\n",
    "    return probs, label\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = random.choice(os.listdir('flowers/test/98/'))\n",
    "img_path= 'flowers/test/98/'+ img\n",
    "with Image.open(img_path) as image:\n",
    "        plt.imshow(image)\n",
    "        \n",
    "probs, classes = predict(img_path,model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "print([cat_to_name[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " TODO: Display an image along with the top 5 classes\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "probs, classes = predict(img_path, model)\n",
    "max_index = np.argmax(probs)\n",
    "max_probability = probs[max_index]\n",
    "label=classes[max_index]\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax1 = plt.subplot2grid((15,9),(0,0),colspan=9,rowspan=9)\n",
    "ax2 = plt.subplot2grid((15,9),(9,2),colspan=5,rowspan=5)\n",
    "\n",
    "image=Image.open(img_path)\n",
    "ax1.axis('off')\n",
    "ax1.set_title(cat_to_name[label])\n",
    "ax1.imshow(image)\n",
    "\n",
    "labels = []\n",
    "for c1 in classes:\n",
    "    labels.append(cat_to_name[c1])\n",
    "    \n",
    "y_pos=np.arange(5)\n",
    "ax2.set_yticks(y_pos)\n",
    "ax2.set_yticklabels(labels)\n",
    "ax2.set_xlabel('probability')\n",
    "ax2.invert_yaxis()\n",
    "ax2.barh(y_pos, probs, xerr=0, align='center',color='blue')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
